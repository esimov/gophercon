Face detection with Go
Gopherconf India 2020

Endre Simo
https://esimov.com
https://github.com/esimov
https://twitter/simo_endre

* Agenda
- What is Pigo?
- Key features
- Technical overview
- Pigo and GoCV (OpenCV) comparision
- Use cases and integrations
- Pupils/eyes localization
- Facial landmark points detection
- Real time demos
- Running the face detector from Python as shared library
- Porting to Webassembly (WASM)

* What is Pigo?

* What is Pigo?
.image assets/pigo_logo.png 300 _
- Computer vision and machine learning library for face detection, pupils/eyes localization and facial landmark points detection
- The only face detection library in the Go ecosystem developed 100% in Go
- The implementation is based on _Pixel_ _Intensity_ _Comparison-based_ _Object_ _detection_ paper

* Why it has been developed?

- Installing OpenCV sometimes can be daunting
- OpenCV is huge, impossible to deploy it on small platforms where space constraints are important

: All the existing libraries in the Go ecosystem are actually bindings to or wrappers around other well known machine learning and computer vision libraries developed mostly in C. Bindings are not cost effective. But more on this topic later.
: There is no need to install platform dependent libraries, no need to compile and build a giant and monolithic OpenCV library only for face detection.

* Key features

What are the benefits of using Pigo over other existing solutions? Just to name a few of them:

- Very lightweight, no requirements for 3rd party modules and external libraries
- Platform independent, one single executable
- Simple and elegant API
- High processing speed
- There is no need for image preprocessing prior detection
- The face detection is based on pixel intensity comparison encoded in the binary file tree structure
- Fast detection of in-plane rotated faces
- Pupils/eyes localization
- Facial landmark points detection

* Technical overview

* Technical overview
- *Pigo*, like the *Viola* *Jones* face detection algorithm is also constructed around cascade decision trees, but the cascade classifier is in binary format
- The role of a classifier is to tell if a face is present in the current region or not
- The classifier consists of a decision tree, where the results of pixel intensity comparison test are in binary format.
- Because the cascades are encoded into a binary tree structure they first need to be unpacked.

* Upacking steps
- Read the depth of each tree and write it into the buffer array.
- Retrieve the number of stages and write it into the buffer array.
- Obtain the scale multiplier (applied after each stage) and write it into the buffer array.
- Obtain the number of trees per stage and write it into the buffer array.
- Obtain the depth of each tree and write it into the buffer array.
- Traverse all the stages of the binary tree
- Read prediction from tree's leaf nodes.

* Unpacking the result
In the end we should get a cascade with the following structure:

        return &PuplocCascade{
            stages:    stages,
            scales:    scales,
            trees:     trees,
            treeDepth: treeDepth,
            treeCodes: treeCodes,
            treePreds: treePreds,
        }, nil

* Classify regions
Next we classify the regions based on the parsed binary data.

For classification we are using a simple pixel intensity comparision test in binary format.

        bintest := func(px1, px2 uint8) int {
            if px1 <= px2 {
                return 1
            }
            return 0
        }
        idx = 2*idx + bintest(pixels[x1], pixels[x2])

The `idx` will be the index in the prediction tree.

_Note_: for in plane rotated faces we are applying the same formula only that we are calculating the rotation angle.

* Run cascade
- An image region is considered being face if it passes all the cascade members. Since this process is limited to a relatively small number of regions, this gains high computation speed.
- During the decision tree scanning each detection is flagged with a detection score.
- An image region is considered as face if the detection score is above a certain threshold (*~0.995*)
- The detector function will return a struct with the following structure

        // Detection struct contains the detection results composed of
        // the row, column, scale factor and the detection score.
        type Detection struct {
            Row   int
            Col   int
            Scale int
            Q     float32
        }

* Cluster detection
- Due to the noisiness of the underlying pixel data, the detector might produce overlaps in detections.
.image assets/pigo_output_without_clustering-1024x819.png 300 _
- The cascade regions are clustered together by aplying an *IoU* (Intersection over Union) formula over the detection results.

* The intersection over union method
    sort.Sort(det(detections))

    calcIoU := func(det1, det2 Detection) float64 {
        // Unpack the position and size of each detection.
        r1, c1, s1 := float64(det1.Row), float64(det1.Col), float64(det1.Scale)
        r2, c2, s2 := float64(det2.Row), float64(det2.Col), float64(det2.Scale)

        overRow := math.Max(0, math.Min(r1+s1/2, r2+s2/2)-math.Max(r1-s1/2, r2-s2/2))
        overCol := math.Max(0, math.Min(c1+s1/2, c2+s2/2)-math.Max(c1-s1/2, c2-s2/2))

        // Return intersection over union.
        return overRow * overCol / (s1*s1 + s2*s2 - overRow*overCol)
    }

* End result
.image assets/pigo_clustering-1024x819.png 550 _

* Pigo and GoCV (OpenCV) comparision

* Benchmark results
    BenchmarkGoCV-4   	       3	 414122553 ns/op	     704 B/op	       1 allocs/op
    BenchmarkPIGO-4   	      10	 173664832 ns/op	       0 B/op	       0 allocs/op
    PASS
    ok  	github.com/esimov/gocv-test	4.530s

.link https://github.com/esimov/pigo-gocv-benchmark

: To have a more accurate benchmark and to measure only the execution time the `b.ResetTimer()` is called to reset the timer so the setup is not counted towards the benchmark.
: For the above test we were using a sample image with a Nasa crew of 17 persons. Both of the libraries have returned exactly the same results, but Pigo was faster and also the memory allocation was way less compared to GoCV

* Use cases and integrations
: Pigo has been successfully integrated into the OpenFaaS platform, easing you out from all the tedious work requested by the installation, configuration of the Go language etc., making possible to expose it as an FaaS function. This means once you have an OpenFaaS platform installed on your local machine with only two commands you have a fully working docker image where Pigo can be used as a serverless function.

* OpenFaaS integration
.image assets/pigo_openfaas.png 350 _

* OpenFaaS integration
.image assets/pigo_openfaas_result.jpg 300 _
.link https://github.com/esimov/pigo-openfaas

* OpenFaaS intergation
.image assets/pigo_openfaas-blur.png 350 _

* OpenFaaS integration
.image assets/pigo_openfaas-blur_result.jpg 400 _
.link https://github.com/esimov/pigo-openfaas-faceblur
.link https://github.com/esimov/stackblur-go

* Other integration
.image assets/caire-example.png

Avoiding face deformation in Caire
.link https://github.com/esimov/caire

* Pupils/eyes localization

* Pupils/eyes localization
.image assets/pigo_puploc.png 550 _

* Short overview
- The implementation pretty much resambles with the face detection method but with few remarkable differences.
: This means that the classifier used for the pupil/eyes detection is generated based on decision trees and the training data is recursively clustered in this fashion until some termination condition is met.
- The detection method (as the face detection) is based on tree esembles.
- As on Pigo face detection, the detection is based on a simple binary test.
- The output of the regression trees might be noisy
- We introduce a random perturbation factor during runtime to outweigh the false positive rates on detection
: There is a problem though: the output of the regression trees might be noisy and unreliable in some special cases like when we are feeding some low quality video frames or images. This is the reason why the method introduces a random perturbation factor during runtime to outweigh the false positive rates on detection. Later on, after the detected face region is classified we sort the perturbations in ascendant order and retrieve the median value of the resulted vector.
.image assets/puploc_perturbation.jpg 200 _

* Sort the perturbations
After the face region has been classified we sort the perturbations in ascendant order.
.image assets/puploc_detector.png 530 _

* Left/right face detection
Same formula for left and rigth eye detection. The sign is flipped on the right eye.

    // left eye
    puploc = &pigo.Puploc{
        Row:      face.Row - int(0.075*float32(face.Scale)),
        Col:      face.Col - int(0.175*float32(face.Scale)),
        Scale:    float32(face.Scale) * 0.25,
        Perturbs: perturb,
    }

    // right eye
    puploc = &pigo.Puploc{
        Row:      face.Row - int(0.075*float32(face.Scale)),
        Col:      face.Col + int(0.185*float32(face.Scale)),
        Scale:    float32(face.Scale) * 0.25,
        Perturbs: perturb,
    }

* Facial landmark points detection

* Facial landmark points detection
.image assets/pigo_landmark.png _ 550